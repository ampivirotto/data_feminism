Questions:

1.  In introducing her idea of the *New Jim Code,* Ruha Benjamin defines
    it in brief as technologies that perpetuate existing inequities
    masquerading as more objective than previous systems. A common
    argument for the neutrality of data is that race should be
    anonymized or excluded from datasets to prevent bias. How might
    Benjamin respond to this claim? In what ways can so-called
    "colorblind" approaches to data and technology reinforce racial
    inequalities rather than eliminate them? What alternatives might
    exist for designing data systems that acknowledge and address racial
    disparities rather than obscuring them?

2.  *Data Feminism* discusses how marginalized communities have used
    data to challenge dominant power structures, highlighting
    initiatives like the Feminicide Database, the Anti-Eviction Mapping
    Project, and Data for Black Lives. How do these initiatives reach
    their intended audiences and translate data activism into real
    change? What challenges do they face in making their work visible,
    accessible, and actionable? Can data-driven activism be truly
    effective without structural change, or does it risk reinforcing
    existing power dynamics?

3.  Ruha Benjamin examines the practice of data sharing in the
    introduction. What are some ways you're currently being surveilled?
    How might the sharing of this information affect other parts of your
    life? Is there any way for data fusion to be done in a way that
    mitigates the harm Bejamin describes?

4.  Benjamin argues that simply fixing biased algorithms is not
    enough---we must rethink the entire system that produces them. What
    does this mean in practical terms? How can individuals or
    institutions challenge racism in technology beyond just improving
    algorithms?

Pick two from among the discussion questions:

1.  In Chapter 2, communications researcher, Candice Lanius\'s blog post
    says \"more data will never be enough to convince those in positions
    of power\", so what can be done to make such people change their
    minds or encourage them to learn and accept research that proves
    things contrary to their beliefs?

2.  How does racial capitalism present itself in relation to hiring
    algorithms? How can data scientists take action by analyzing the
    impacts of racist hiring practices?

3.  In Chapter 2 of Data Feminism, they discuss how certain algorithms
    such as risk-assessment for recidivism are inherently racially
    biased. Consider some ways that we could create a more fair system
    for determining these types of important information. Is it possible
    to create an algorithm or automated process that is unbiased?

4.  Upper-class white Americans have the ability to shield their
    children from technology, while lower-class people of color lack
    access to technology and tech literacy. How does this influence the
    different effect technology has on people of color and white people?
    If the roles were reversed (the upper class didn\'t have access to
    technology and the lower class tended to opt out), would that change
    this effect, and how? How and why might that situation occur?

5.  Algorithms are not allowed to decide mortgage eligibility because
    they regularly reject qualified Black applicants. Is it necessary
    therefore, to have algorithms make major decisions in people\'s
    lives (criminal risk, mortgage applications, etc)?

6.  Both Data Feminism and Race After Technology argue that power is
    embedded in data and technological systems, often reinforcing
    existing social hierarchies. One recent example of this is the
    flagged words in NSF grant applications, where certain terms related
    to diversity, equity, and inclusion have been scrutinized or
    discouraged, reflecting broader political and institutional power
    struggles. Discuss possible strategies for challenging these forms
    of power utilizing data and technology. Can you think of other
    spaces where language or data has been controlled in ways that
    reinforce dominant power structures?

7.  Inspired by \"The New Jim Code\", what is your name -- what is the
    origin of this name, what does it carry. And what do you expect to
    find online regarding your name? Do you think that your name would
    be received \"pleasantly\" or \"unpleasantly\" by the search engine?

8.  How do you think Benjamin's discussion of Silicon Valley culture
    would change in light of Facebook's recent policy changes regarding
    content moderation? How does this fit into ideas about power in data
    and computer science?

9.  Chapter 2 of Data Feminism discusses the process of auditing
    algorithms in research and journalism to uncover data-driven
    revelations in the way of systematic racism and bias. What can be
    done to force accountability for these systematic injustices? What
    justifies a "meaningful response from institutions that have vested
    interest in maintaining the status quo?"

10. In the beginning of The New Jim Code, Benjamin discusses how
    whiteness is viewed as the norm, giving a sort of racial
    invisibility. How might this common belief / assumption hinder
    attempts to pursue data justice? How does our understanding of norms
    potentially limit our ability to achieve justice and liberation?

11. Benjamin suggests \"thin description\" as a possible solution for
    over-surveillance. How would thin description affect the issue of
    risk assessment discussed in Data Feminism, seeing as risk
    assessment focuses on biased data from past conglomerates, rather
    than meaningful information about the actual subjects it analyzes?
    Is thick surveillance still problematic when subjects are being
    analyzed based on data that doesn\'t necessarily apply to them?

12. Benjamin introduces the concept of \"imagined objectivity\" in the
    context of data driven systems, however this concept can be applied
    outside of just this context, in what other places does imagined
    objectivity come into play and how do previous forms of this issue
    influence its affect on data driven systems?

13. Both the Race After Technology reading and Chapter 2 of Data
    Feminism touch on attempts to create "technical fixes" to racial
    biases that often fail. Can these algorithmic or "data-driven
    solutions" ever exist free of human bias? How does the
    prioritization of "efficiency over equity" stand in the way of
    addressing algorithmic discrimination?
